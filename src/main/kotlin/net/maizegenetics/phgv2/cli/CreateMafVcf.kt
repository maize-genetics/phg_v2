package net.maizegenetics.phgv2.cli

import biokotlin.genome.*
import biokotlin.seq.NucSeq
import biokotlin.seqIO.NucSeqIO
import com.github.ajalt.clikt.core.CliktCommand
import com.github.ajalt.clikt.parameters.options.*
import htsjdk.variant.variantcontext.VariantContext
import htsjdk.variant.vcf.VCFAltHeaderLine
import htsjdk.variant.vcf.VCFHeaderLine
import htsjdk.variant.vcf.VCFHeaderVersion
import net.maizegenetics.phgv2.utils.*
import net.maizegenetics.phgv2.utils.Position
import org.apache.logging.log4j.LogManager
import java.io.File

data class HVCFRecordMetadata(val sampleName: String, val refSeq : String = "", val asmSeq : String = "",
                              val refContig : String, val refStart: Int, val refEnd: Int,
                              val asmRegions: List<Pair<Position,Position>>)
data class DisplayRegion(val contig: String, val start: Int, val end: Int)


class CreateMafVcf : CliktCommand(help = "Create g.vcf and h.vcf files from AnchorWave MAF files") {

    private val myLogger = LogManager.getLogger(CreateMafVcf::class.java)
    val bed by option(help = "BED file with entries that define the haplotype boundaries")
        .required()

    val referenceFile by option(help = "Path to local Reference FASTA file")
        .required()

    val mafDir by option(help = "MAF file directory")
        .required()

    val outputDir by option("-o", "--output-dir", help = "Name for output VCF file Directory")
        .required()

    val dbPath by option(help = "Folder name where TileDB datasets and AGC record is stored.  If not provided, the current working directory is used")
        .default("")

    val metricsFile by option("--metrics-file", help = "Path where the vcf metrics file will be written. By default writes to output-dir/VCFMetrics.tsv")
        .default("")

    val skipMetrics by option("--skip-metrics", help = "If this flag is set, do not calculate vcf metrics.")
        .switch(
            "--skip-metrics" to true
        ).default(false)

    val condaEnvPrefix by option (help = "Prefix for the conda environment to use.  If provided, this should be the full path to the conda environment.")
        .default("")

    val legacyMafFile by option(help = "Flag to be backwards compatible with old MAF files generated by anchorwave before version 1.2.3.")
        .flag(default = false)

    /**
     * Function to create the ASM hVCF and gVCF.
     * It will first use Biokotlin to build the gVCF and then will use the BED file to extract out the hVCF information.
     * if [twoGvcfs] is true, then the output will be split into two gvcf files, one for each gamete.
     */
    private fun createASMHvcfs(
        dbPath: String,
        bedFileName: String,
        referenceFileName: String,
        mafDirName: String,
        outputDirName: String,
        metricsFile: String,
        skipMetrics: Boolean = false,
        twoGvcfs: Boolean = false,
        legacyMafFile: Boolean = false
    ) {
        val mafToGVCFObject = MAFToGVCF()

        // load the bed file into some data structure
        val ranges = loadRanges(bedFileName)
        myLogger.info("CreateASMHvcfs: calling buildRefGenomeSeq")
        val refGenomeSequence = buildRefGenomeSeq(referenceFileName)

        // ContigList is needed for sorting the variants.
        // In Biokotlin, these are sorted by the method that calls
        // getVariantContextsfromMAF() in MAFToGVCF.kt. We call MAFTOgVCF.getVariantContextsfromMAF()
        // directly, so must sort the contigs here.
        val contigList = refGenomeSequence.keys.toList().sorted()

        // loop through the maf files in mafDirName and getGVCFVariantsFromMafFile
        File(mafDirName).walk().filter { !it.isHidden && !it.isDirectory }
            .filter { it.extension == "maf" }
            .forEach { originalFileName ->
                myLogger.info("CreateASMHvcfs: processing ${originalFileName.absolutePath}")
                val sampleName = originalFileName.nameWithoutExtension //This will likely need to change in the future
                val gvcfVariants = getGVCFVariantsFromMafFile(mafToGVCFObject,refGenomeSequence, originalFileName.absolutePath, originalFileName.nameWithoutExtension, twoGvcfs=twoGvcfs, legacyMafFile=legacyMafFile)
                //export the gvcfRecords
                if (gvcfVariants.size == 1){
                    myLogger.info("createASMHvcfs: gvcfVariants.size == 1")
                    val sampleName = gvcfVariants.keys.first()

                    processGameteGVCFToHVCF(gvcfVariants.values.first(), mafToGVCFObject, sampleName, sampleName, arrayOf("${outputDirName}/${originalFileName.nameWithoutExtension}.g.vcf"), 0, refGenomeSequence, dbPath, ranges, outputDirName, originalFileName)

                } else if (gvcfVariants.size == 2) {
                    myLogger.info("createASMHvcfs: gvcfVariants.size == 2")
                    val gvcfOutput = "${outputDirName}/${originalFileName.nameWithoutExtension}.g.vcf"
                    val outputNames = MAFToGVCF().twoOutputFiles(gvcfOutput)
                    gvcfVariants.entries.forEachIndexed { index, (name, variants) ->
                        processGameteGVCFToHVCF(
                            variants,
                            mafToGVCFObject,
                            sampleName,
                            name,
                            outputNames,
                            index,
                            refGenomeSequence,
                            dbPath,
                            ranges,
                            outputDirName,
                            originalFileName
                        )
                    }

                }

            }
        // calculate vcf metrics, unless skipMetrics flag has been set
        if(!skipMetrics) {
            CalcVcfMetrics().calculateVcfMetrics(outputDir, metricsFile)
        }

    }

    /**
     * Function to process the VariantInfo GVCF objects into VariantContexts and then into hvcf variants
     */
    private fun processGameteGVCFToHVCF(
        variants: List<AssemblyVariantInfo>,
        mafToGVCFObject: MAFToGVCF,
        sampleName: String,
        exportName: String,
        outputNames: Array<String>,
        index: Int,
        refGenomeSequence: Map<String, NucSeq>,
        dbPath: String,
        ranges: List<Pair<Position, Position>>,
        outputDirName: String,
        originalFileName: File
    ) {
        val sortedVariants = variants.sortedBy { variant -> Position(variant.chr, variant.startPos) }

        exportVariantInfo(exportName, sortedVariants, outputNames[index], refGenomeSequence, setOf(),mafToGVCFObject)
        bgzipAndIndexGVCFfile(outputNames[index])
        val asmHeaderLines = mutableMapOf<String, VCFHeaderLine>()
        //convert the GVCF records into hvcf records
        val hvcfVariants = convertGVCFToHVCFVariantInfo(
            dbPath,
            sampleName,
            ranges,
            sortedVariants,
            refGenomeSequence,
            asmHeaderLines,
            condaEnvPrefix
        )
        val asmHeaderSet = asmHeaderLines.values.toSet()
        //export the hvcfRecords
        exportVariantContext(
            sampleName,
            hvcfVariants,
            "${outputDirName}/${originalFileName.nameWithoutExtension}.h.vcf",
            refGenomeSequence,
            asmHeaderSet
        )
        //bgzip the files
        bgzipAndIndexGVCFfile("${outputDirName}/${originalFileName.nameWithoutExtension}.h.vcf")
    }

    // Function to load in the reference using Biokotlin
    fun buildRefGenomeSeq(referenceFileName: String) : Map<String, NucSeq> {
        return NucSeqIO(referenceFileName).readAll()
    }

    /**
     * Simple Wrapper Function to call biokotlin's MAFToGVCF.getVariantContextsfromMAF
     * The parameters to BioKotlin's (version 0.10) getVariantContextsfromMAF are:
     * 1. [mafFileName] - the name of the MAF file
     * 2. [refGenomeSequence] - the reference genome sequence
     * 3. [sampleName] - the name of the sample
     * 4. [fillGaps] - whether to fill in the gaps in the MAF file, default is false
     * 5. [twoGvcfs] - whether to split the output into two gvcf files, default false
     * 6. [outJustGT] - whether to only output the GT field, default false
     * 7. [outputType] - either gvcf or vcf (BioKotlin doesn't currently have h.vcf, default is gvcf)
     *
     */
    private fun getGVCFVariantsFromMafFile(mafToGVCFObject: MAFToGVCF,refSeq: Map<String,NucSeq>, mafFileName : String,
                                           sampleName: String, fillGaps: Boolean = false, twoGvcfs: Boolean = false, legacyMafFile: Boolean = false) : Map<String,List<AssemblyVariantInfo>> {
        return mafToGVCFObject.getVariantContextsfromMAF(
            mafFileName,
            refSeq,
            sampleName,
            fillGaps,
            twoGvcfs,
            anchorwaveLegacy = legacyMafFile
        )
    }

    /**
     * Function to convert a GVCF file into an HCVF file
     */
    fun convertGVCFToHVCF(dbPath: String,sampleName: String, bedRanges : List<Pair<Position,Position>>, gvcfVariants: List<VariantContext>,
                          refGenomeSequence : Map<String, NucSeq>, agcArchiveName: String, asmHeaders: MutableMap<String,VCFHeaderLine>,condaEnvPrefix:String = "") : List<VariantContext> {
        // group the gvcfVariants by contig
        val gvcfVariantsByContig = gvcfVariants.groupBy { it.contig }

        val bedRegionsByContig = bedRanges.groupBy { it.first.contig }


        myLogger.info("in convertGVCFToHVCF: sort and call converGVCFToHVCFForChrom")
        return gvcfVariantsByContig.keys
            .sortedWith(compareBy(SeqRangeSort.alphaThenNumberSort){ name:String -> name}) //Need to do a sort here as we need to make sure we process the chromosomes in
            .filter { bedRegionsByContig.containsKey(it) }
            .flatMap { convertGVCFToHVCFForChrom(dbPath, sampleName, bedRegionsByContig[it]!!, refGenomeSequence, agcArchiveName, gvcfVariantsByContig[it]!!, asmHeaders,condaEnvPrefix) }
    }

    private fun convertGVCFToHVCFForChrom(dbPath: String, sampleName: String, bedRanges: List<Pair<Position,Position>>, refGenomeSequence: Map<String, NucSeq>, agcArchiveName: String, variantContexts: List<VariantContext>, asmHeaders: MutableMap<String,VCFHeaderLine>, condaEnvPrefix:String = "" ) : List<VariantContext> {
        
        /**
         * Loop through the bed file
         * Loop through the gvcf records as well
         *
         * We need to determine if our BED region overlaps with the gvcf record
         * To do this we need to collect the gvcf records into their corresponding bed Regions
         * Then from those collected regions, we take the first and last ones and resize based on the bed regions to get the asm_Start and asm_End
         * Then extract the sequence out of the AGC archive and md5 hash it
         * Then call the createHVCFRecord with this information
         */
        myLogger.info("in convertGVCFToHVCFForChrom: bedRanges.size = ${bedRanges.size}")
        val outputVariantMetadata = mutableListOf<HVCFRecordMetadata>()
        var currentVariantIdx = 0
        for(region in bedRanges) {
            val regionStart = region.first.position
            val regionEnd = region.second.position
            val regionChrom = region.first.contig
            val tempVariants = mutableListOf<VariantContext>()

            check(regionChrom in refGenomeSequence.keys) { "Chromosome $regionChrom not found in reference" }

            //Need to subtract here as the Biokotlin NucSeq is 0 based
            val refRangeSeq = refGenomeSequence[regionChrom]!![regionStart-1..regionEnd-1]

            while (currentVariantIdx < variantContexts.size) {
                val currentVariant = variantContexts[currentVariantIdx]

                //check different cases for the variant
                //If variant is fully contained in Bed region add to temp list and increment currentVariantIdx
                //If variant is partially contained in Bed region add to temp list do not increment as we need to see if the next bed also overlaps
                //If variant is not contained in Bed region, skip and do not increment as we need to see if the next bed overlaps
                if(VariantContextUtils.bedRegionContainedInVariant(region, currentVariant)) {
                    outputVariantMetadata.add(
                        convertGVCFRecordsToHVCFMetaData(
                            sampleName,
                            region,
                            refRangeSeq,
                            listOf(currentVariant)
                        )
                    )
                    tempVariants.clear()
                    break
                }
                if(VariantContextUtils.variantFullyContained(region, currentVariant)) {
                    //This is the case where the variant is completely contained within the region
                    tempVariants.add(currentVariant)
                    currentVariantIdx++
                }
                else if(VariantContextUtils.variantPartiallyContainedStart(region,currentVariant)) {
                    tempVariants.add(currentVariant)
                    break
                }
                else if(VariantContextUtils.variantPartiallyContainedEnd(region, currentVariant)) {
                    tempVariants.add(currentVariant)
                    currentVariantIdx++
                }
                else if(VariantContextUtils.variantAfterRegion(region, currentVariant)) {
                    //write out what is in tempVariants
                    if(tempVariants.isNotEmpty()) {
                        outputVariantMetadata.add(
                            convertGVCFRecordsToHVCFMetaData(sampleName,
                                region,
                                refRangeSeq,
                                tempVariants
                            )
                        )

                        tempVariants.clear()
                    }
                    //move up Bed region
                    break
                }
                else { //this is the case if the Variant is behind the BED region
                    //move up Variant
                    currentVariantIdx++
                }
            }

            if(tempVariants.isNotEmpty()) {
                outputVariantMetadata.add(convertGVCFRecordsToHVCFMetaData(
                    sampleName,
                    region,
                    refRangeSeq,
                    tempVariants
                ))
                tempVariants.clear()
            }
        }

        val metaDataWithSequence = addSequencesToMetaData(dbPath, outputVariantMetadata, condaEnvPrefix)
        val outputVariants = convertMetaDataToHVCFContexts(metaDataWithSequence, asmHeaders, dbPath)

        return outputVariants
    }

    /**
     * Function to convert a GVCF file into an HCVF file
     */
    fun convertGVCFToHVCFVariantInfo(dbPath: String,sampleName: String, bedRanges : List<Pair<Position,Position>>, gvcfVariants: List<AssemblyVariantInfo>,
                          refGenomeSequence : Map<String, NucSeq>, asmHeaders: MutableMap<String,VCFHeaderLine>,condaEnvPrefix:String = "") : List<VariantContext> {
        // group the gvcfVariants by contig
        val gvcfVariantsByContig = gvcfVariants.groupBy { it.chr }

        val bedRegionsByContig = bedRanges.groupBy { it.first.contig }


        myLogger.info("in convertGVCFToHVCF: sort and call converGVCFToHVCFForChrom")
        return gvcfVariantsByContig.keys
            .sortedWith(compareBy(SeqRangeSort.alphaThenNumberSort){ name:String -> name}) //Need to do a sort here as we need to make sure we process the chromosomes in
            .filter { bedRegionsByContig.containsKey(it) }
            .flatMap { convertGVCFToHVCFForChromVaraintInfo(dbPath, sampleName, bedRegionsByContig[it]!!, refGenomeSequence, gvcfVariantsByContig[it]!!, asmHeaders,condaEnvPrefix) }
    }


    private fun convertGVCFToHVCFForChromVaraintInfo(dbPath: String, sampleName: String, bedRanges: List<Pair<Position,Position>>, refGenomeSequence: Map<String, NucSeq>, variantInfos: List<AssemblyVariantInfo>, asmHeaders: MutableMap<String,VCFHeaderLine>, condaEnvPrefix:String = "" ) : List<VariantContext> {

        /**
         * Loop through the bed file
         * Loop through the gvcf records as well
         *
         * We need to determine if our BED region overlaps with the gvcf record
         * To do this we need to collect the gvcf records into their corresponding bed Regions
         * Then from those collected regions, we take the first and last ones and resize based on the bed regions to get the asm_Start and asm_End
         * Then extract the sequence out of the AGC archive and md5 hash it
         * Then call the createHVCFRecord with this information
         */
        myLogger.info("in convertGVCFToHVCFForChrom: bedRanges.size = ${bedRanges.size}")
        val outputVariantMetadata = mutableListOf<HVCFRecordMetadata>()
        var currentVariantIdx = 0
        for(region in bedRanges) {
            val regionStart = region.first.position
            val regionEnd = region.second.position
            val regionChrom = region.first.contig
            val tempVariants = mutableListOf<AssemblyVariantInfo>()

            check(regionChrom in refGenomeSequence.keys) { "Chromosome $regionChrom not found in reference" }

            //Need to subtract here as the Biokotlin NucSeq is 0 based
            val refRangeSeq = refGenomeSequence[regionChrom]!![regionStart-1..regionEnd-1]

            while (currentVariantIdx < variantInfos.size) {
                val currentVariantInfo = variantInfos[currentVariantIdx]

                //check different cases for the variant
                //If variant is fully contained in Bed region add to temp list and increment currentVariantIdx
                //If variant is partially contained in Bed region add to temp list do not increment as we need to see if the next bed also overlaps
                //If variant is not contained in Bed region, skip and do not increment as we need to see if the next bed overlaps
                if(AssemblyVariantInfoUtils.bedRegionContainedInVariantInfo(region, currentVariantInfo)) {
                    outputVariantMetadata.add(
                        convertGVCFRecordsToHVCFMetaDataVariantInfo(
                            sampleName,
                            region,
                            refRangeSeq,
                            listOf(currentVariantInfo)
                        )
                    )
                    tempVariants.clear()
                    break
                }
                if(AssemblyVariantInfoUtils.variantInfoFullyContained(region, currentVariantInfo)) {
                    //This is the case where the variant is completely contained within the region
                    tempVariants.add(currentVariantInfo)
                    currentVariantIdx++
                }
                else if(AssemblyVariantInfoUtils.variantInfoPartiallyContainedStart(region,currentVariantInfo)) {
                    tempVariants.add(currentVariantInfo)
                    break
                }
                else if(AssemblyVariantInfoUtils.variantInfoPartiallyContainedEnd(region, currentVariantInfo)) {
                    tempVariants.add(currentVariantInfo)
                    currentVariantIdx++
                }
                else if(AssemblyVariantInfoUtils.variantInfoAfterRegion(region, currentVariantInfo)) {
                    //write out what is in tempVariants
                    if(tempVariants.isNotEmpty()) {
                        outputVariantMetadata.add(
                            convertGVCFRecordsToHVCFMetaDataVariantInfo(sampleName,
                                region,
                                refRangeSeq,
                                tempVariants
                            )
                        )

                        tempVariants.clear()
                    }
                    //move up Bed region
                    break
                }
                else { //this is the case if the Variant is behind the BED region
                    //move up Variant
                    currentVariantIdx++
                }
            }

            if(tempVariants.isNotEmpty()) {
                outputVariantMetadata.add(convertGVCFRecordsToHVCFMetaDataVariantInfo(
                    sampleName,
                    region,
                    refRangeSeq,
                    tempVariants
                ))
                tempVariants.clear()
            }
        }

        val metaDataWithSequence = addSequencesToMetaData(dbPath, outputVariantMetadata, condaEnvPrefix)
        val outputVariants = convertMetaDataToHVCFContexts(metaDataWithSequence, asmHeaders, dbPath)

        return outputVariants
    }



    /**
     * Function to extract all the needed information out of the ASM gVCF record and put them into HVCFRecordMetadata objects
     * This will first try to resize the positions based on the ref start position and then will extract out all the other information.
     */
    private fun convertGVCFRecordsToHVCFMetaData(sampleName: String, region: Pair<Position,Position>, refRangeSeq: NucSeq, variants: List<VariantContext> ) : HVCFRecordMetadata {
        //Take the first and the last variantContext
        val firstVariant = variants.first()
        val lastVariant = variants.last()

        //val check strandedness of the variants
        val firstStrand = firstVariant.getAttributeAsString("ASM_Strand","+")

        val lastStrand = lastVariant.getAttributeAsString("ASM_Strand","+")
        //Resize the first and last variantContext ASM start and end based on the regions
        var newASMStart = resizeVariantContext(firstVariant, region.first.position, firstStrand)
        if(newASMStart == -1) {
            newASMStart = if(firstStrand == "+") firstVariant.getAttributeAsInt("ASM_Start",region.first.position)
                else firstVariant.getAttributeAsInt("ASM_End",region.first.position)
        }

        var newASMEnd = resizeVariantContext(lastVariant, region.second.position, lastStrand)
        if(newASMEnd == -1) {
            newASMEnd = if(lastStrand == "+") lastVariant.getAttributeAsInt("ASM_End",region.second.position)
                else lastVariant.getAttributeAsInt("ASM_Start",region.second.position)
        }

        val regions = buildNewAssemblyRegions(newASMStart,newASMEnd,variants)


        return HVCFRecordMetadata(sampleName=sampleName, refSeq = refRangeSeq.toString(), asmSeq = "",
            refContig = region.first.contig, refStart = region.first.position, refEnd = region.second.position,
            regions)

    }



    /**
     * Function to extract all the needed information out of the ASM gVCF record and put them into HVCFRecordMetadata objects
     * This will first try to resize the positions based on the ref start position and then will extract out all the other information.
     */
    private fun convertGVCFRecordsToHVCFMetaDataVariantInfo(sampleName: String, region: Pair<Position,Position>, refRangeSeq: NucSeq, variants: List<AssemblyVariantInfo> ) : HVCFRecordMetadata {
        //Take the first and the last variantVariantInfo
        val firstVariant = variants.first()
        val lastVariant = variants.last()

        //val check strandedness of the variants
        val firstStrand = firstVariant.asmStrand

        val lastStrand = lastVariant.asmStrand
        //Resize the first and last variantContext ASM start and end based on the regions
        var newASMStart = resizeVariantInfo(firstVariant, region.first.position, firstStrand)
        if(newASMStart == -1) {
            newASMStart = if(firstStrand == "+") firstVariant.asmStart
            else firstVariant.asmEnd
        }

        var newASMEnd = resizeVariantInfo(lastVariant, region.second.position, lastStrand)
        if(newASMEnd == -1) {
            newASMEnd = if(lastStrand == "+") lastVariant.asmEnd
            else lastVariant.asmStart
        }

        val regions = buildNewAssemblyRegionsVariantInfo(newASMStart,newASMEnd,variants)


        return HVCFRecordMetadata(sampleName=sampleName, refSeq = refRangeSeq.toString(), asmSeq = "",
            refContig = region.first.contig, refStart = region.first.position, refEnd = region.second.position,
            regions)

    }

    /**
     * Function to build the new assembly region coordinates based on the new Start and end and the list of VariantContexts
     * Any consecutive regions should be merged together so we do not make the eventual string too long
     * The output will be a List<Pair<Position,Position>> which will be the new coordinates for the all the  assembly regions
     */
    fun buildNewAssemblyRegions(newStart: Int, newEnd: Int, variants: List<VariantContext>) : List<Pair<Position,Position>> {
        val variantsConverted = variants.map { convertVariantContextToPositionRange(it) }

        //resize the first and last position based on the strand
        val resizedFirst = resizePositionRange(variantsConverted.first(),newStart,true)
        val resizedLast = resizePositionRange(variantsConverted.last(),newEnd,false)

        //merge the first and last with the rest of the variants
        val mergedVariants = mutableListOf<Pair<Position,Position>>()
        if(variantsConverted.size == 1) {
            val resizedFirstAndLast = resizePositionRange(resizePositionRange(variantsConverted.first(), newStart, true), newEnd, false)
            mergedVariants.add(resizedFirstAndLast)
        } else {
            mergedVariants.add(resizedFirst) // add the first variant
            if (variantsConverted.size > 2) { // add any variants in the middle
                mergedVariants.addAll(variantsConverted.subList(1, variantsConverted.size - 1))
            }
            mergedVariants.add(resizedLast) // add the last variant
        }

        //merge the consecutive regions
        val mergedConsecutiveVariants = mergeConsecutiveRegions(mergedVariants)

        return mergedConsecutiveVariants
    }


    /**
     * Function to build the new assembly region coordinates based on the new Start and end and the list of VariantContexts
     * Any consecutive regions should be merged together so we do not make the eventual string too long
     * The output will be a List<Pair<Position,Position>> which will be the new coordinates for the all the  assembly regions
     */
    fun buildNewAssemblyRegionsVariantInfo(newStart: Int, newEnd: Int, variants: List<AssemblyVariantInfo>) : List<Pair<Position,Position>> {
        val variantsConverted = variants.map { convertVariantInfoToPositionRange(it) }

        //resize the first and last position based on the strand
        val resizedFirst = resizePositionRange(variantsConverted.first(),newStart,true)
        val resizedLast = resizePositionRange(variantsConverted.last(),newEnd,false)

        //merge the first and last with the rest of the variants
        val mergedVariants = mutableListOf<Pair<Position,Position>>()
        if(variantsConverted.size == 1) {
            val resizedFirstAndLast = resizePositionRange(resizePositionRange(variantsConverted.first(), newStart, true), newEnd, false)
            mergedVariants.add(resizedFirstAndLast)
        } else {
            mergedVariants.add(resizedFirst) // add the first variant
            if (variantsConverted.size > 2) { // add any variants in the middle
                mergedVariants.addAll(variantsConverted.subList(1, variantsConverted.size - 1))
            }
            mergedVariants.add(resizedLast) // add the last variant
        }

        //merge the consecutive regions
        val mergedConsecutiveVariants = mergeConsecutiveRegions(mergedVariants)

        return mergedConsecutiveVariants
    }


    /**
     * Strand aware function to merge together consecutive assembly regions.  This is done to reduce the number of entries in the hvcf alt header.
     */
    fun mergeConsecutiveRegions(variants: List<Pair<Position,Position>>) : List<Pair<Position,Position>> {
        val mergedConsecutiveVariants = mutableListOf<Pair<Position,Position>>()
        var currentStart = variants.first().first
        var currentEnd = variants.first().second
        for(i in 1 until variants.size) {
            val nextStart = variants[i].first
            val nextEnd = variants[i].second

            //Check to see if the next region is only 1 bp long.  If so we need to check both normal and inverted boundaries and extend if it makes sense, if not reset the currentStart and currentEnd
            if(nextStart.position == nextEnd.position) {
                //Check to see if the next region is on the + strand
                //Using nextStart here as it equals nextEnd
                if(nextStart.position == currentEnd.position + 1 || nextStart.position == currentEnd.position -1) {
                    currentEnd = nextStart
                }
                else {
                    mergedConsecutiveVariants.add(Pair(currentStart,currentEnd))
                    currentStart = nextStart
                    currentEnd = nextEnd
                }
            }
            else if(currentEnd < currentStart && nextEnd < nextStart) {
                //This is the case where we have a variant that is on the - strand
                //We need to check if the next variant is consecutive
                if(nextStart.position == (currentEnd.position - 1)) {
                    currentEnd = nextEnd
                }
                else {
                    mergedConsecutiveVariants.add(Pair(currentStart,currentEnd))
                    currentStart = nextStart
                    currentEnd = nextEnd
                }
            }
            else if(nextStart.position == (currentEnd.position + 1)) {
                currentEnd = nextEnd
            }
            else {
                mergedConsecutiveVariants.add(Pair(currentStart,currentEnd))
                currentStart = nextStart
                currentEnd = nextEnd
            }
        }
        mergedConsecutiveVariants.add(Pair(currentStart,currentEnd))
        return mergedConsecutiveVariants
    }

    /**
     * Function to convert a VariantContext into a Pair<Position,Position> which will be the assembly starts and ends of the variantContext
     */
    fun convertVariantContextToPositionRange(variant: VariantContext) : Pair<Position,Position> {
        //get out the assembly coords
        val contig = variant.getAttributeAsString("ASM_Chr","")
        val start = variant.getAttributeAsInt("ASM_Start",variant.start)
        val end = variant.getAttributeAsInt("ASM_End",variant.end)
        return Pair(Position(contig, start), Position(contig, end))
    }

    /**
     * Function to convert a AssemblyVariantInfo into a Pair<Position,Position> which will be the assembly starts and ends of the AssemblyVariantInfo
     */
    fun convertVariantInfoToPositionRange(variant: AssemblyVariantInfo) : Pair<Position,Position> {
        //get out the assembly coords
        val contig = variant.asmChrom
        val start = variant.asmStart
        val end = variant.asmEnd
        return Pair(Position(contig, start), Position(contig, end))
    }

    /**
     * Function to resize the Position range based on the new position.  If isFirst is true then it will resize the start position, otherwise it will resize the end position
     */
    fun resizePositionRange(positionRange: Pair<Position,Position>, newPosition : Int, isFirst: Boolean) : Pair<Position,Position> {
        return if(isFirst) {
            //Slide the start position to the new position
            Pair(Position(positionRange.first.contig,newPosition),positionRange.second)
        } else {
            //Slide the end position to the new position
            Pair(positionRange.first,Position(positionRange.second.contig,newPosition))
        }
    }


    /**
     * This function will bulk load sequences in from the AGC record and then will associate the returned sequences
     * with the metadata record which contains the coordiantes for the query and will add in the asmSeq.
     */
    private fun addSequencesToMetaData(dbPath: String, metadata: List<HVCFRecordMetadata>, condaEnvPrefix:String="") : List<HVCFRecordMetadata> {
        //get out the assembly coordinates and build them into the regions
        val metaDataToRangeLookup = metadata.map {
            val queries = mutableListOf<String>()
            val displayNames = mutableListOf<String>()

            for(range in it.asmRegions) {
                if(range.first.position-1 > range.second.position-1) {
                    queries.add("${range.first.contig}@${it.sampleName}:${range.second.position-1}-${range.first.position-1}")
                    displayNames.add("${range.first.contig}:${range.second.position-1}-${range.first.position-1}")
                }
                else {
                    queries.add("${range.first.contig}@${it.sampleName}:${range.first.position - 1}-${range.second.position - 1}")
                    displayNames.add("${range.first.contig}:${range.first.position-1}-${range.second.position-1}")
                }
            }

            Triple(it,queries, displayNames)
        }

        val ranges = metaDataToRangeLookup.flatMap { it.second }

        val seqs = retrieveAgcContigs(dbPath,ranges,condaEnvPrefix)

        return metaDataToRangeLookup.map { it.first.copy(asmSeq = buildSeq(seqs,it.third,it.first)) } //This is a useful way to keep things immutable
    }


    /**
     * Function to build the haplotype sequence based on the list of display regions and the given haplotype sequence object.
     * The sequence is already extracted out of AGC and stored in the seqs map.
     * The seqs map is keyed by a Pair of (sampleName, displayRegion) and the value is the NucSeq object.
     * The Pair may look something like ("B97", "1:1-1000") or ("B97", "chr1")
     */
    fun buildSeq(seqs: Map<Pair<String,String>,NucSeq> ,displayRegions : List<String>, hvcfRecordMetadata: HVCFRecordMetadata) : String {
        val hapSeqRegions = hvcfRecordMetadata.asmRegions

        return displayRegions.mapIndexed{ idx, currentDisplayRegion ->
            val currentHapSeqRegion = hapSeqRegions[idx]

            val seq = seqs[Pair(hvcfRecordMetadata.sampleName,currentDisplayRegion)]!!

            //Means it is the first region
            if(currentHapSeqRegion.first.position > currentHapSeqRegion.second.position) {
                //Means it needs to be reverse complemented
                seq.reverse_complement().seq()
            }
            else {
                seq.seq()
            }
        }.joinToString()
    }

    /**
     * Simple function to convert the all the HVCFRecordMetadata records into VariantContext records
     */
    fun convertMetaDataToHVCFContexts(metaData: List<HVCFRecordMetadata>, asmHeaders: MutableMap<String,VCFHeaderLine>, dbPath:String): List<VariantContext> {
        return metaData.map { convertMetaDataRecordToHVCF(it, asmHeaders, dbPath) }
    }

    /**
     * Simple function to convert a single metadata record into a VariantContext.
     * This will also create the ALT tag and add it to the asmHeaders object for use during export.
     */
    private fun convertMetaDataRecordToHVCF(metaDataRecord: HVCFRecordMetadata, asmHeaders: MutableMap<String, VCFHeaderLine>, dbPath: String): VariantContext {
        val assemblyHaplotypeSeq:String = metaDataRecord.asmSeq
        //md5 hash the assembly sequence
        val assemblyHaplotypeHash = getChecksumForString(assemblyHaplotypeSeq)
        check(metaDataRecord.refSeq.isNotEmpty()) { "Reference sequence is empty" }
        //md5 has the refSequence
        val refSeqHash = getChecksumForString(metaDataRecord.refSeq)

        //create the asmHeader lines
        if(!asmHeaders.containsKey(assemblyHaplotypeHash)) {
            asmHeaders[assemblyHaplotypeHash] =
            VCFAltHeaderLine(
                "<ID=${assemblyHaplotypeHash}, Description=\"haplotype data for line: ${metaDataRecord.sampleName}\">," +
                        "Source=\"${dbPath}/assemblies.agc\",SampleName=\"${metaDataRecord.sampleName}\"," +
                        "Regions=\"${metaDataRecord.asmRegions.map { "${it.first.contig}:${it.first.position}-${it.second.position}" }.joinToString(",")}\"," +
                        "Checksum=\"${assemblyHaplotypeHash}\",RefChecksum=\"${refSeqHash}\",RefRange=\"${metaDataRecord.refContig}:${metaDataRecord.refStart}-${metaDataRecord.refEnd}\">",
                VCFHeaderVersion.VCF4_2
            )
        } else {
           myLogger.info("convertMetaDataRecordToHVCF: asmHeaders already contains key ${assemblyHaplotypeHash}")
        }


        //build a variant context of the HVCF with the hashes
        return createHVCFRecord(metaDataRecord.sampleName, Position(metaDataRecord.refContig,metaDataRecord.refStart),
            Position(metaDataRecord.refContig, metaDataRecord.refEnd ),
            Pair(metaDataRecord.refSeq[0].toString(), assemblyHaplotypeHash))
    }


    /**
     * Function will return -1 if unable to resize the variantcontext due to its type(mostly an INDEL)
     * If the requested position is outside of the current variants coordinates it will return the ASM_Start for + strand and ASM_End for - strand
     */
    fun resizeVariantContext(variant: VariantContext, position: Int, strand : String) : Int {
        //check to see if the variant is either a RefBlock or is a SNP with equal lengths
        return if(isVariantResizable(variant)) {
            when {
                position < variant.start -> variant.getAttributeAsInt("ASM_Start",variant.start)
                position > variant.end -> variant.getAttributeAsInt("ASM_End",variant.end)
                strand == "+" -> {
                    val offset = position - variant.start
                    variant.getAttributeAsInt("ASM_Start",variant.start) + offset
                }
                strand == "-" -> {
                    val offset = position - variant.start
                    variant.getAttributeAsInt("ASM_Start",variant.end) - offset
                }
                else -> -1
            }
        } else {
            -1
        }
    }

    /**
     * Function will return -1 if unable to resize the variantcontext due to its type(mostly an INDEL)
     * If the requested position is outside of the current variants coordinates it will return the ASM_Start for + strand and ASM_End for - strand
     */
    fun resizeVariantInfo(variant: AssemblyVariantInfo, position: Int, strand : String) : Int {
        //check to see if the variant is either a RefBlock or is a SNP with equal lengths
        return if(isVariantInfoResizable(variant)) {
            when {
                position < variant.startPos -> variant.asmStart
                position > variant.endPos -> variant.asmEnd
                strand == "+" -> {
                    val offset = position - variant.startPos
                    variant.asmStart + offset
                }
                strand == "-" -> {
                    val offset = position - variant.startPos
                    variant.asmStart - offset
                }
                else -> -1
            }
        } else {
            -1
        }
    }

    /**
     * Function to check if a variant is resizable.  Only RefBlocks and SNPs are resizable
     */
    fun isVariantResizable(variant: VariantContext) : Boolean {
        return when {
            variant.getReference().baseString.length == 1 && variant.end - variant.start > 0 && variant.type == VariantContext.Type.SYMBOLIC -> true //refBlock
            variant.reference.baseString.length == variant.getAlternateAllele(0).baseString.length -> true //This covers both SNPs and multiallelic polymorphisms
            else -> false
        }
    }

    /**
     * Function to check if a variant is resizable.  Only RefBlocks and SNPs are resizable
     */
    fun isVariantInfoResizable(variant: AssemblyVariantInfo) : Boolean {
        return when {
            variant.refAllele.length == 1 && variant.endPos - variant.startPos > 0 -> true //refBlock
            variant.refAllele.length == variant.altAllele.length -> true //This covers both SNPs and multiallelic polymorphisms
            else -> false
        }
    }

    override fun run() {

        logCommand(this)

        val dbPath = if (dbPath.isBlank()) {
            System.getProperty("user.dir")
        } else {
            dbPath
        }

        // Verify the tiledbURI
        // If it doesn't an exception will be thrown
        val validDB = verifyURI(dbPath,"hvcf_dataset",condaEnvPrefix)
        if(metricsFile != "") {
            // twoGvcfs is not an option for the CLI, so we will always set it to false
            createASMHvcfs(dbPath, bed, referenceFile, mafDir, outputDir, metricsFile, skipMetrics, false,legacyMafFile)
        } else {
            createASMHvcfs(dbPath, bed, referenceFile, mafDir, outputDir, "$outputDir/VCFMetrics.tsv", skipMetrics, false,legacyMafFile)
        }

    }

}